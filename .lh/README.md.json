{
    "sourceFile": "README.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 3,
            "patches": [
                {
                    "date": 1758642289491,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1758647039095,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,171 +1,333 @@\n-# zod-to-from\n+# zod-to-from (ZTF)\n \n-<!-- automd:badges color=yellow -->\n+[![npm version](https://img.shields.io/npm/v/zod-to-from.svg)](https://www.npmjs.com/package/zod-to-from)\n+[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n+[![Build Status](https://img.shields.io/badge/build-passing-brightgreen.svg)](https://github.com/unjs/zod-to-from)\n \n-[![npm version](https://img.shields.io/npm/v/zod-to-from?color=yellow)](https://npmjs.com/package/zod-to-from)\n-[![npm downloads](https://img.shields.io/npm/dm/zod-to-from?color=yellow)](https://npm.chart.dev/zod-to-from)\n+ZTF is a universal I/O conversion layer centered on Zod schemas. The core\n+philosophy is that Zod is the single source of truth, and all other formats are\n+merely views of that truth. It aims to make Zod the universal intermediate\n+representation for all application I/O.\n \n-<!-- /automd -->\n+## Core Philosophy\n \n-A collection of to/from adapters that convert between I/O formats and Zod-validated objects. The library is designed with a \"one schema in the middle, many edges around it\" philosophy, providing a schema-centric I/O hub for JavaScript. It is a build-less, ESM-only library using `.mjs` files with JSDoc for type safety.\n+The library operates on two primary primitives: `from(format) -> zod` and\n+`to(format) <- zod`. All transformations are deterministic, using canonical\n+ordering and stable serialization to ensure reproducibility. The system is built\n+on the invariant that for any given data, `to(X, from(X, data))` is\n+approximately equal to the original data, with any lossiness being explicitly\n+declared and tracked.\n \n-### ‚ú® Features\n+## ‚ú® Features\n \n-  * **Schema-Centric:** Uses a single Zod schema as the central contract for all I/O operations.\n-  * **Massive Converter Catalog:** Supports a wide range of formats through optional packs, including Office documents, data analytics formats, config files, and knowledge graphs.\n-  * **Symmetric API:** Provides a simple and symmetrical API with three core functions: `parseFrom`, `formatTo`, and `convert`.\n-  * **Deterministic Outputs:** Enforces deterministic I/O with stable key ordering and consistent formatting policies for dates and numbers.\n-  * **Buildless by Design:** Uses `.mjs` and JSDoc to ensure a build-free, portable runtime that works in Node, Deno, and edge environments.\n-  * **Optional AI Adapters:** Can leverage the Vercel AI SDK and Ollama to normalize \"messy\" formats like Office documents into a structured schema.\n-  * **First-Class RDF/Turtle Support:** Treats Turtle as a universal Intermediate Representation (IR), unlocking capabilities for knowledge-driven automation, governance, and provenance.\n-  * **Monorepo Structure:** Organized as a pnpm workspace with a small core library and optional packs for different format categories.\n+- **Zod at the Center**: Your Zod schema is the canonical model; all I/O is\n+  validated against it\n+- **Deterministic I/O**: Transformations are designed to be reproducible with\n+  canonical ordering and stable serialization\n+- **First-Class Provenance**: Automatically capture the source, transform chain,\n+  and checksums for any operation\n+- **Content Addressing**: Artifacts can be keyed by a hash of their schema,\n+  options, and content for verifiable storage\n+- **Streaming First**: The API is designed around async iterable decoders and\n+  encoders to handle large payloads efficiently\n+- **Integrated Validation & Repair**: Parsing and validation occur in a single\n+  pass, with an optional repair loop to auto-fix and re-validate data\n+- **Partial Parsing**: Selectively extract a subset of data by projecting a\n+  partial Zod schema\n+- **Composable Pipeline**: Adapters are designed as composable functors,\n+  allowing for pipelines like `from(A) |> map |> to(B)`\n+- **Schema Versioning**: Includes support for typed transforms to migrate\n+  schemas from vN to vN+1\n+- **Typed Error Model**: Errors are explicitly typed as DecodeError,\n+  ValidateError, or LossyWarning\n+- **Security by Design**: Features safe parsers, resource caps, sandboxable\n+  runners, and deterministic timeouts for untrusted inputs\n+- **Governance & Observability**: Produces exportable audit logs (JSONL, Turtle)\n+  and provides per-stage timings and anomaly flags\n \n-### üöÄ Quick Start\n+## üöÄ Quick Start\n \n-**1. Installation**\n+The programmatic core is pure ESM, with side effects isolated in adapters.\n \n-```bash\n-# Install the core library and zod\n-npm i zod-to-from zod\n+### Programmatic API\n \n-# Install optional packs as needed\n-npm i ztf-pack-office ztf-pack-data ztf-pack-graph\n-```\n-\n-**2. Usage**\n-\n ```javascript\n+// Two primitives: parseFrom() and formatTo()\n+import { parseFrom, formatTo, convert } from 'zod-to-from';\n import { z } from 'zod';\n-import { convert, parseFrom, formatTo } from 'zod-to-from';\n \n-// 1) Define your Zod schema\n-const Config = z.object({\n-  host: z.string(),\n-  port: z.number().int().positive(),\n-  debug: z.boolean().default(false)\n+// Define your schema\n+const UserSchema = z.object({\n+  name: z.string(),\n+  age: z.number(),\n+  active: z.boolean().default(true),\n });\n \n-// 2) Parse from a format (e.g., YAML) into a validated object\n-const obj = await parseFrom(Config, 'yaml', `\n-host: api.example.com\n-port: 8443\n-debug: true\n-`);\n+// Parse and validate in one pass\n+const userObject = await parseFrom(\n+  UserSchema,\n+  'json',\n+  '{\"name\":\"Alice\",\"age\":30}'\n+);\n \n-// 3) Format the object into another format (e.g., TOML)\n-const toml = await formatTo(Config, 'toml', obj);\n+// Format a validated object to another format\n+const userYaml = await formatTo(UserSchema, 'yaml', userObject);\n \n-// 4) Convert between formats in a single step\n-const toml2 = await convert(Config, { from: 'yaml', to: 'toml' }, `\n-host: api.example.com\n-port: 8443\n-`);\n+// Convert between formats\n+const userCsv = await convert(\n+  UserSchema,\n+  { from: 'json', to: 'csv' },\n+  '{\"name\":\"Alice\",\"age\":30}'\n+);\n ```\n \n-### üì¶ API\n+### CLI\n \n-  * `parseFrom(schema, format, input, opts?)`: Parses input from a specified format into a Zod-validated object.\n-  * `formatTo(schema, format, data, opts?)`: Formats a validated object into the specified output format.\n-  * `convert(schema, { from, to }, input, opts?)`: A one-shot function to convert from an input format to an output format.\n-  * `registerAdapter(name, adapter)`: Allows for adding custom format converters at runtime.\n-  * `listAdapters()`: Returns a list of available adapters.\n+ZTF provides a simple noun-verb command-line interface.\n \n-### üìö Converter Packs (The 80/20 \"Dark Matter\")\n+```bash\n+# Convert a source file from one format to another through a schema\n+ztf convert --from json --to yaml --schema ./schemas/user.mjs#UserSchema --in input.json --out output.yaml\n \n-ZTF covers the \"dark matter\" of heterogeneous I/O formats through a series of optional packs.\n+# Parse a file with schema validation\n+ztf parse --schema ./schemas/config.mjs#Config --from yaml --in config.yaml --out config.json\n \n-| Pack | Formats | Shape |\n-| --- | --- | --- |\n-| **Office & Exec Outputs** | `docx-table`, `pptx-slides`, `xlsx`, `pdf-table`, `md`, `html`, `csv` | doc, table |\n-| **Data & Analytics** | `json`, `ndjson`, `parquet`, `arrow`, `avro`, `protobuf`, `sqlite` | tree, records, table |\n-| **Graph & Knowledge** | `ttl`, `nq`, `jsonld`, `plantuml`, `mermaid`, `openapi`, `jsonschema` | graph, diagram |\n-| **DevOps & Config** | `yaml`, `toml`, `ini`, `env`, `dockerfile`, `compose`, `k8s` | tree, records |\n-| **Nunjucks** | `njk`, `md`, `html`, `puml`, `ttl`, `frontmatter` (parse) | doc |\n-| **Communications** | `ics`, `vcard`, `eml`, `msgpack`, `har`, `curl` | calendar, contact, message |\n-| **Media & Meta** | `exif`, `id3`, `base64`, `zip`, `tar`, `pdf-text` | tree, blob, doc |\n-| **Geo & Time** | `geojson`, `topojson`, `kml`, `gpx`, `wkt` | tree |\n+# Format data to a specific format\n+ztf format --schema ./schemas/data.mjs#DataSchema --to csv --in data.json --out data.csv\n \n-### ü§ñ AI-Assisted Adapters\n+# List available adapters\n+ztf list\n+```\n \n-For \"messy\" formats with implicit structure, ZTF provides optional AI-powered adapters.\n+## üì¶ Supported Formats (The 80/20)\n \n-  * **`office-ai` Pack:** Uses the Vercel AI SDK and Ollama to parse formats like `.docx`, `.pptx`, and `.xlsx` by extracting their content and normalizing it into a target Zod schema.\n-  * **Ingestion Only:** This AI-powered normalization is used only for `parseFrom` operations. The `formatTo` operation for creating documents remains deterministic.\n-  * **Provenance:** Outputs from AI adapters are tagged with metadata, such as the LLM model used, for auditability.\n+ZTF prioritizes broad coverage of high-value \"dark matter\" formats before\n+tackling the long tail.\n \n-### üîß CLI (Optional)\n+### Text Formats\n \n-ZTF includes an optional CLI for command-line conversions.\n+- **JSON**, **JSONL/NDJSON**, **YAML**, **TOML**, **CSV/TSV**, **INI**\n \n-```bash\n-# Parse a YAML file into a JSON object\n-npx ztf parse --schema ./schemas/config.mjs#Config --from yaml --in config.yaml --out config.json\n+### Binary Formats\n \n-# Format a JSON object into a TOML file\n-npx ztf format --schema ./schemas/config.mjs#Config --to toml --in config.json --out config.toml\n+- **Parquet**, **Arrow IPC**, **Avro**, **Protobuf**, **MessagePack**, **CBOR**,\n+  **Ion**\n \n-# Convert a CSV file directly to an XLSX spreadsheet\n-npx ztf convert --schema ./schemas/report.mjs#Report[] --from csv --to xlsx --in data.csv --out out.xlsx\n+### Web & API Schemas\n+\n+- **OpenAPI/Swagger** ‚Üî Zod\n+- **JSON Schema** ‚Üî Zod\n+- **GraphQL SDL** ‚Üî Zod\n+\n+### Database & ORM Mappings\n+\n+- **SQL DDL** ‚Üî Zod\n+- **Prisma**, **Drizzle**, **TypeORM**, **Mongoose** mappings\n+\n+### Search & Index Schemas\n+\n+- **Elasticsearch** mappings ‚Üî Zod\n+- **Meilisearch** & **Algolia** shapes\n+\n+### Files & Office Documents (LLM-Assisted)\n+\n+- **PDF**, **Docx**, **XLSX**, and **HTML** can be parsed into Zod objects using\n+  Vercel AI SDK guardrails\n+\n+### Knowledge & Graph Layer\n+\n+- **Turtle/N3** ‚Üî Zod\n+- **RDF triples** ‚Üî Zod records\n+- **SHACL** ‚Üî Zod constraints\n+\n+### Diagrams\n+\n+- **PlantUML** structural views (e.g., class diagrams) ‚Üî Zod projections\n+\n+## üèóÔ∏è Architecture\n+\n+ZTF follows a monolithic structure with clear separation of concerns:\n+\n ```\n+src/\n+‚îú‚îÄ‚îÄ core/                    # Core API and registry\n+‚îÇ   ‚îú‚îÄ‚îÄ registry.mjs        # Adapter registry and utilities\n+‚îÇ   ‚îî‚îÄ‚îÄ main.mjs           # Main API functions (parseFrom, formatTo, convert)\n+‚îú‚îÄ‚îÄ adapters/               # Format converters\n+‚îÇ   ‚îú‚îÄ‚îÄ json.mjs           # JSON adapter\n+‚îÇ   ‚îú‚îÄ‚îÄ yaml.mjs           # YAML adapter\n+‚îÇ   ‚îú‚îÄ‚îÄ csv.mjs            # CSV adapter\n+‚îÇ   ‚îú‚îÄ‚îÄ data.mjs           # Data analytics formats\n+‚îÇ   ‚îú‚îÄ‚îÄ office.mjs         # Office document formats\n+‚îÇ   ‚îú‚îÄ‚îÄ graph.mjs          # Knowledge graph formats\n+‚îÇ   ‚îî‚îÄ‚îÄ nunjucks.mjs       # Template rendering\n+‚îú‚îÄ‚îÄ mappers/                # Schema bridges\n+‚îÇ   ‚îú‚îÄ‚îÄ workflow.mjs       # Workflow-specific mappings\n+‚îÇ   ‚îî‚îÄ‚îÄ kpi.mjs            # KPI-specific mappings\n+‚îú‚îÄ‚îÄ cli/                    # Command-line interface\n+‚îÇ   ‚îú‚îÄ‚îÄ cli.mjs            # Main CLI entry point\n+‚îÇ   ‚îî‚îÄ‚îÄ commands/          # Individual command implementations\n+‚îî‚îÄ‚îÄ index.mjs              # Main library entry point\n+```\n \n-## Usage\n+## üõ°Ô∏è Security and Governance\n \n-Install the package:\n+- **Safe Execution**: Adapters are designed with safe parsers and can be run in\n+  sandboxed environments with deterministic timeouts and size limits for\n+  untrusted inputs\n+- **Typed Configuration**: All configuration, including for adapters, is handled\n+  via Zod schemas to prevent untyped options\n+- **Auditability**: Governance audit logs are exportable as JSONL or Turtle,\n+  making them ready for board-level reporting\n+- **Stability**: Adapters follow strict semantic versioning, and schemas can be\n+  frozen per tag to ensure stability\n \n-```sh\n-# ‚ú® Auto-detect (supports npm, yarn, pnpm, deno and bun)\n-npx nypm install zod-to-from\n+## üõ†Ô∏è Extensibility\n+\n+ZTF is designed to be extensible from the ground up. An adapter kit provides\n+scaffolds, conformance tests, and fixtures to help you quickly add support for\n+new formats.\n+\n+### Creating Custom Adapters\n+\n+```javascript\n+import { registerAdapter } from 'zod-to-from';\n+\n+const customAdapter = {\n+  async parse(input, opts = {}) {\n+    // Parse input to data\n+    const data = parseCustomFormat(input);\n+    return {\n+      data,\n+      metadata: {\n+        format: 'custom',\n+        inputSize: input.length,\n+        ...opts,\n+      },\n+    };\n+  },\n+\n+  async format(data, opts = {}) {\n+    // Format data to string\n+    const output = formatCustomFormat(data);\n+    return {\n+      data: output,\n+      metadata: {\n+        format: 'custom',\n+        outputSize: output.length,\n+        ...opts,\n+      },\n+    };\n+  },\n+\n+  supportsStreaming: false,\n+  isAI: false,\n+  version: '1.0.0',\n+};\n+\n+registerAdapter('custom', customAdapter);\n ```\n \n-Import:\n+## üìã API Reference\n \n-<!-- automd:jsimport cdn name=\"zod-to-from\" -->\n+### Core Functions\n \n-**ESM** (Node.js, Bun, Deno)\n+#### `parseFrom(schema, format, input, options?)`\n \n-```js\n-import { parseFrom, formatTo, convert } from \"zod-to-from\";\n+Parse input from a specified format into a Zod-validated object.\n+\n+#### `formatTo(schema, format, data, options?)`\n+\n+Format a Zod-validated object to a specified output format.\n+\n+#### `convert(schema, conversion, input, options?)`\n+\n+Convert data from one format to another with schema validation.\n+\n+#### `registerAdapter(name, adapter)`\n+\n+Register a new adapter for a specific format.\n+\n+#### `listAdapters()`\n+\n+List all registered adapter names.\n+\n+### Options\n+\n+```typescript\n+interface ZTFOptions {\n+  adapter?: Record<string, unknown>; // Custom options for the specific adapter\n+  validate?: boolean; // Whether to validate the output against the schema\n+  includeProvenance?: boolean; // Whether to include provenance metadata in result\n+  deterministic?: boolean; // Whether to enforce deterministic output\n+  streaming?: boolean; // Whether to use streaming for large datasets\n+}\n ```\n \n-**CDN** (Deno, Bun and Browsers)\n+## üß™ Testing\n \n-```js\n-import { parseFrom, formatTo, convert } from \"https://esm.sh/zod-to-from\";\n+```bash\n+# Run tests\n+pnpm test\n+\n+# Run tests with coverage\n+pnpm test --coverage\n+\n+# Run linting\n+pnpm lint\n+\n+# Fix linting issues\n+pnpm lint:fix\n ```\n \n-<!-- /automd -->\n+### ü§ñ AI Adapter Testing\n \n-## Development\n+The AI adapters include comprehensive tests that verify integration with Ollama\n+models. These tests are **opt-in only** to keep the regular test suite fast:\n \n-<details>\n+```bash\n+# Run AI adapter tests (requires Ollama running locally)\n+pnpm test:ai\n \n-<summary>local development</summary>\n+# Run AI adapter tests in watch mode\n+pnpm test:ai:watch\n \n-- Clone this repository\n-- Install latest LTS version of [Node.js](https://nodejs.org/en/)\n-- Enable [Corepack](https://github.com/nodejs/corepack) using `corepack enable`\n-- Install dependencies using `pnpm install`\n-- Run interactive tests using `pnpm dev`\n+# Run regular tests (AI tests are skipped by default)\n+pnpm test\n+```\n \n-</details>\n+**Prerequisites for AI tests:**\n \n-## License\n+- Ollama installed and running locally\n+- At least one model available (e.g., `qwen3-coder`, `qwen3:8b`)\n+- Test files available in\n+  `node_modules/.pnpm/mammoth@*/node_modules/mammoth/test/test-data/`\n \n-<!-- automd:contributors license=MIT -->\n+The AI tests verify:\n \n-Published under the [MIT](https://github.com/unjs/zod-to-from/blob/main/LICENSE) license.\n-Made by [community](https://github.com/unjs/zod-to-from/graphs/contributors) üíõ\n-<br><br>\n-<a href=\"https://github.com/unjs/zod-to-from/graphs/contributors\">\n-<img src=\"https://contrib.rocks/image?repo=unjs/zod-to-from\" />\n-</a>\n+- ‚úÖ Real document processing (DOCX files)\n+- ‚úÖ Multiple model support\n+- ‚úÖ Custom prompt handling\n+- ‚úÖ Schema validation\n+- ‚úÖ Error handling\n \n-<!-- /automd -->\n+## üìÑ License\n \n-<!-- automd:with-automd -->\n+MIT License - see [LICENSE](LICENSE) for details.\n \n+## ü§ù Contributing\n+\n+Contributions are welcome! Please read our contributing guidelines and submit\n+pull requests to our repository.\n+\n+## üìö Documentation\n+\n+- [API Reference](./docs/api.md)\n+- [Adapter Development Guide](./docs/adapters.md)\n+- [CLI Usage Guide](./docs/cli.md)\n+- [Security Best Practices](./docs/security.md)\n+\n ---\n \n-_ü§ñ auto updated with [automd](https://automd.unjs.io)_\n-\n-<!-- /automd -->\n+**zod-to-from** - Making Zod the universal intermediate representation for all\n+application I/O.\n"
                },
                {
                    "date": 1758649662745,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,333 +1,301 @@\n-# zod-to-from (ZTF)\n+# Zod-to-From (ZTF)\n \n-[![npm version](https://img.shields.io/npm/v/zod-to-from.svg)](https://www.npmjs.com/package/zod-to-from)\n-[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n-[![Build Status](https://img.shields.io/badge/build-passing-brightgreen.svg)](https://github.com/unjs/zod-to-from)\n+> **A comprehensive format conversion library with Zod schema validation**\n \n-ZTF is a universal I/O conversion layer centered on Zod schemas. The core\n-philosophy is that Zod is the single source of truth, and all other formats are\n-merely views of that truth. It aims to make Zod the universal intermediate\n-representation for all application I/O.\n+ZTF is a powerful, extensible library that provides seamless conversion between\n+various data formats while ensuring type safety through Zod schema validation.\n+Whether you're working with JSON, YAML, CSV, or specialized formats like GPX,\n+KML, or Office documents, ZTF has you covered.\n \n-## Core Philosophy\n+## üöÄ Features\n \n-The library operates on two primary primitives: `from(format) -> zod` and\n-`to(format) <- zod`. All transformations are deterministic, using canonical\n-ordering and stable serialization to ensure reproducibility. The system is built\n-on the invariant that for any given data, `to(X, from(X, data))` is\n-approximately equal to the original data, with any lossiness being explicitly\n-declared and tracked.\n+- **42+ Format Adapters** - Support for JSON, YAML, CSV, XML, Office documents,\n+  geospatial data, and more\n+- **Zod Schema Validation** - Type-safe data conversion with runtime validation\n+- **AI-Powered Adapters** - Intelligent parsing for complex documents using\n+  Ollama\n+- **Streaming Support** - Handle large datasets efficiently\n+- **Provenance Tracking** - Audit trail for all conversions\n+- **Extensible Architecture** - Easy to add custom adapters\n+- **Zero Dependencies** - Core library has no external dependencies\n+- **JSDoc Documentation** - Comprehensive type information\n \n-## ‚ú® Features\n+## üì¶ Installation\n \n-- **Zod at the Center**: Your Zod schema is the canonical model; all I/O is\n-  validated against it\n-- **Deterministic I/O**: Transformations are designed to be reproducible with\n-  canonical ordering and stable serialization\n-- **First-Class Provenance**: Automatically capture the source, transform chain,\n-  and checksums for any operation\n-- **Content Addressing**: Artifacts can be keyed by a hash of their schema,\n-  options, and content for verifiable storage\n-- **Streaming First**: The API is designed around async iterable decoders and\n-  encoders to handle large payloads efficiently\n-- **Integrated Validation & Repair**: Parsing and validation occur in a single\n-  pass, with an optional repair loop to auto-fix and re-validate data\n-- **Partial Parsing**: Selectively extract a subset of data by projecting a\n-  partial Zod schema\n-- **Composable Pipeline**: Adapters are designed as composable functors,\n-  allowing for pipelines like `from(A) |> map |> to(B)`\n-- **Schema Versioning**: Includes support for typed transforms to migrate\n-  schemas from vN to vN+1\n-- **Typed Error Model**: Errors are explicitly typed as DecodeError,\n-  ValidateError, or LossyWarning\n-- **Security by Design**: Features safe parsers, resource caps, sandboxable\n-  runners, and deterministic timeouts for untrusted inputs\n-- **Governance & Observability**: Produces exportable audit logs (JSONL, Turtle)\n-  and provides per-stage timings and anomaly flags\n+```bash\n+# Using pnpm (recommended)\n+pnpm add zod-to-from\n \n-## üöÄ Quick Start\n+# Using npm\n+npm install zod-to-from\n \n-The programmatic core is pure ESM, with side effects isolated in adapters.\n+# Using yarn\n+yarn add zod-to-from\n+```\n \n-### Programmatic API\n+## üéØ Quick Start\n \n ```javascript\n-// Two primitives: parseFrom() and formatTo()\n import { parseFrom, formatTo, convert } from 'zod-to-from';\n import { z } from 'zod';\n \n // Define your schema\n const UserSchema = z.object({\n   name: z.string(),\n   age: z.number(),\n-  active: z.boolean().default(true),\n+  email: z.string().email(),\n });\n \n-// Parse and validate in one pass\n-const userObject = await parseFrom(\n-  UserSchema,\n-  'json',\n-  '{\"name\":\"Alice\",\"age\":30}'\n-);\n+// Parse JSON data\n+const jsonData = '{\"name\": \"Alice\", \"age\": 30, \"email\": \"alice@example.com\"}';\n+const user = await parseFrom(UserSchema, 'json', jsonData);\n+console.log(user); // { name: \"Alice\", age: 30, email: \"alice@example.com\" }\n \n-// Format a validated object to another format\n-const userYaml = await formatTo(UserSchema, 'yaml', userObject);\n+// Format to YAML\n+const yamlOutput = await formatTo(UserSchema, 'yaml', user);\n+console.log(yamlOutput);\n+// name: Alice\n+// age: 30\n+// email: alice@example.com\n \n // Convert between formats\n-const userCsv = await convert(\n+const csvInput = 'name,age,email\\nBob,25,bob@example.com';\n+const jsonOutput = await convert(\n   UserSchema,\n-  { from: 'json', to: 'csv' },\n-  '{\"name\":\"Alice\",\"age\":30}'\n+  { from: 'csv', to: 'json' },\n+  csvInput\n );\n+console.log(jsonOutput);\n+// [{\"name\": \"Bob\", \"age\": 25, \"email\": \"bob@example.com\"}]\n ```\n \n-### CLI\n+## üìö Documentation\n \n-ZTF provides a simple noun-verb command-line interface.\n+- **[API Reference](docs/api/README.md)** - Complete API documentation\n+- **[Adapter Guide](docs/adapters/README.md)** - All available format adapters\n+- **[Examples](docs/examples/README.md)** - Usage examples and tutorials\n+- **[Guides](docs/guides/README.md)** - Advanced usage patterns\n+- **[Contributing](docs/contributing/README.md)** - How to contribute\n \n-```bash\n-# Convert a source file from one format to another through a schema\n-ztf convert --from json --to yaml --schema ./schemas/user.mjs#UserSchema --in input.json --out output.yaml\n+## üîå Available Adapters\n \n-# Parse a file with schema validation\n-ztf parse --schema ./schemas/config.mjs#Config --from yaml --in config.yaml --out config.json\n+### Core Data Formats\n \n-# Format data to a specific format\n-ztf format --schema ./schemas/data.mjs#DataSchema --to csv --in data.json --out data.csv\n+- **JSON** - JavaScript Object Notation\n+- **YAML** - YAML Ain't Markup Language\n+- **TOML** - Tom's Obvious, Minimal Language\n+- **CSV** - Comma-Separated Values\n+- **NDJSON** - Newline Delimited JSON\n \n-# List available adapters\n-ztf list\n-```\n+### Office & Documents\n \n-## üì¶ Supported Formats (The 80/20)\n+- **DOCX** - Microsoft Word documents (with AI assistance)\n+- **PPTX** - PowerPoint presentations\n+- **XLSX** - Excel spreadsheets\n+- **PDF** - PDF text extraction and table support\n+- **HTML** - HyperText Markup Language\n+- **Markdown** - Markdown formatting\n \n-ZTF prioritizes broad coverage of high-value \"dark matter\" formats before\n-tackling the long tail.\n+### Geospatial\n \n-### Text Formats\n+- **GPX** - GPS Exchange Format\n+- **KML** - Keyhole Markup Language\n+- **TopoJSON** - Topological JSON\n+- **WKT** - Well-Known Text geometries\n \n-- **JSON**, **JSONL/NDJSON**, **YAML**, **TOML**, **CSV/TSV**, **INI**\n+### Communications\n \n-### Binary Formats\n+- **cURL** - HTTP request commands\n+- **EML** - Email messages\n+- **ICS** - Calendar events\n+- **vCard** - Contact information\n+- **MessagePack** - Binary serialization\n \n-- **Parquet**, **Arrow IPC**, **Avro**, **Protobuf**, **MessagePack**, **CBOR**,\n-  **Ion**\n+### DevOps & Config\n \n-### Web & API Schemas\n+- **Docker Compose** - Container orchestration\n+- **Dockerfile** - Container definitions\n+- **Kubernetes** - K8s manifests\n+- **Terraform HCL** - Infrastructure as code\n+- **Environment Variables** - .env files\n+- **INI** - Configuration files\n \n-- **OpenAPI/Swagger** ‚Üî Zod\n-- **JSON Schema** ‚Üî Zod\n-- **GraphQL SDL** ‚Üî Zod\n+### Graph & Knowledge\n \n-### Database & ORM Mappings\n+- **JSON-LD** - Linked Data\n+- **Turtle** - RDF serialization\n+- **N-Quads** - RDF quads\n+- **PlantUML** - Diagram definitions\n \n-- **SQL DDL** ‚Üî Zod\n-- **Prisma**, **Drizzle**, **TypeORM**, **Mongoose** mappings\n+### Media & Archives\n \n-### Search & Index Schemas\n+- **EXIF** - Image metadata\n+- **ID3** - Audio metadata\n+- **TAR** - Archive format\n+- **ZIP** - Compressed archives\n \n-- **Elasticsearch** mappings ‚Üî Zod\n-- **Meilisearch** & **Algolia** shapes\n+### Templating\n \n-### Files & Office Documents (LLM-Assisted)\n+- **Nunjucks** - Template engine\n+- **Frontmatter** - Document metadata\n \n-- **PDF**, **Docx**, **XLSX**, and **HTML** can be parsed into Zod objects using\n-  Vercel AI SDK guardrails\n+## üß† AI-Powered Adapters\n \n-### Knowledge & Graph Layer\n+ZTF includes AI-powered adapters that use Ollama for intelligent document\n+parsing:\n \n-- **Turtle/N3** ‚Üî Zod\n-- **RDF triples** ‚Üî Zod records\n-- **SHACL** ‚Üî Zod constraints\n+```javascript\n+import { parseFrom } from 'zod-to-from';\n+import { z } from 'zod';\n \n-### Diagrams\n+const DocumentSchema = z.object({\n+  title: z.string(),\n+  summary: z.string(),\n+  keyPoints: z.array(z.string()),\n+});\n \n-- **PlantUML** structural views (e.g., class diagrams) ‚Üî Zod projections\n+// AI-assisted DOCX parsing\n+const docxBuffer = fs.readFileSync('document.docx');\n+const parsed = await parseFrom(DocumentSchema, 'docx-ai', docxBuffer, {\n+  adapter: {\n+    model: 'qwen3-coder',\n+    prompt: 'Extract the main points from this document',\n+  },\n+});\n+```\n \n-## üèóÔ∏è Architecture\n+## üîÑ Streaming Support\n \n-ZTF follows a monolithic structure with clear separation of concerns:\n+Handle large datasets efficiently with streaming:\n \n+```javascript\n+import { parseFrom } from 'zod-to-from';\n+\n+const result = await parseFrom(Schema, 'csv', largeCsvData, {\n+  streaming: true,\n+});\n ```\n-src/\n-‚îú‚îÄ‚îÄ core/                    # Core API and registry\n-‚îÇ   ‚îú‚îÄ‚îÄ registry.mjs        # Adapter registry and utilities\n-‚îÇ   ‚îî‚îÄ‚îÄ main.mjs           # Main API functions (parseFrom, formatTo, convert)\n-‚îú‚îÄ‚îÄ adapters/               # Format converters\n-‚îÇ   ‚îú‚îÄ‚îÄ json.mjs           # JSON adapter\n-‚îÇ   ‚îú‚îÄ‚îÄ yaml.mjs           # YAML adapter\n-‚îÇ   ‚îú‚îÄ‚îÄ csv.mjs            # CSV adapter\n-‚îÇ   ‚îú‚îÄ‚îÄ data.mjs           # Data analytics formats\n-‚îÇ   ‚îú‚îÄ‚îÄ office.mjs         # Office document formats\n-‚îÇ   ‚îú‚îÄ‚îÄ graph.mjs          # Knowledge graph formats\n-‚îÇ   ‚îî‚îÄ‚îÄ nunjucks.mjs       # Template rendering\n-‚îú‚îÄ‚îÄ mappers/                # Schema bridges\n-‚îÇ   ‚îú‚îÄ‚îÄ workflow.mjs       # Workflow-specific mappings\n-‚îÇ   ‚îî‚îÄ‚îÄ kpi.mjs            # KPI-specific mappings\n-‚îú‚îÄ‚îÄ cli/                    # Command-line interface\n-‚îÇ   ‚îú‚îÄ‚îÄ cli.mjs            # Main CLI entry point\n-‚îÇ   ‚îî‚îÄ‚îÄ commands/          # Individual command implementations\n-‚îî‚îÄ‚îÄ index.mjs              # Main library entry point\n-```\n \n-## üõ°Ô∏è Security and Governance\n+## üìä Provenance Tracking\n \n-- **Safe Execution**: Adapters are designed with safe parsers and can be run in\n-  sandboxed environments with deterministic timeouts and size limits for\n-  untrusted inputs\n-- **Typed Configuration**: All configuration, including for adapters, is handled\n-  via Zod schemas to prevent untyped options\n-- **Auditability**: Governance audit logs are exportable as JSONL or Turtle,\n-  making them ready for board-level reporting\n-- **Stability**: Adapters follow strict semantic versioning, and schemas can be\n-  frozen per tag to ensure stability\n+Track the history of your data transformations:\n \n-## üõ†Ô∏è Extensibility\n+```javascript\n+const result = await parseFrom(Schema, 'json', data, {\n+  includeProvenance: true,\n+});\n \n-ZTF is designed to be extensible from the ground up. An adapter kit provides\n-scaffolds, conformance tests, and fixtures to help you quickly add support for\n-new formats.\n+console.log(result.provenance);\n+// {\n+//   timestamp: \"2024-01-01T12:00:00.000Z\",\n+//   adapter: \"json\",\n+//   version: \"0.1.0\",\n+//   schemaHash: \"abc123...\"\n+// }\n+```\n \n-### Creating Custom Adapters\n+## üõ†Ô∏è Advanced Usage\n \n+### Custom Adapters\n+\n ```javascript\n import { registerAdapter } from 'zod-to-from';\n \n-const customAdapter = {\n+registerAdapter('custom', {\n   async parse(input, opts = {}) {\n-    // Parse input to data\n-    const data = parseCustomFormat(input);\n-    return {\n-      data,\n-      metadata: {\n-        format: 'custom',\n-        inputSize: input.length,\n-        ...opts,\n-      },\n-    };\n+    // Your parsing logic\n+    return { data: parsedData, metadata: {} };\n   },\n-\n   async format(data, opts = {}) {\n-    // Format data to string\n-    const output = formatCustomFormat(data);\n-    return {\n-      data: output,\n-      metadata: {\n-        format: 'custom',\n-        outputSize: output.length,\n-        ...opts,\n-      },\n-    };\n+    // Your formatting logic\n+    return { data: formattedString, metadata: {} };\n   },\n-\n   supportsStreaming: false,\n   isAI: false,\n   version: '1.0.0',\n-};\n-\n-registerAdapter('custom', customAdapter);\n+});\n ```\n \n-## üìã API Reference\n+### Error Handling\n \n-### Core Functions\n+```javascript\n+import { parseFrom } from 'zod-to-from';\n+import { z } from 'zod';\n \n-#### `parseFrom(schema, format, input, options?)`\n-\n-Parse input from a specified format into a Zod-validated object.\n-\n-#### `formatTo(schema, format, data, options?)`\n-\n-Format a Zod-validated object to a specified output format.\n-\n-#### `convert(schema, conversion, input, options?)`\n-\n-Convert data from one format to another with schema validation.\n-\n-#### `registerAdapter(name, adapter)`\n-\n-Register a new adapter for a specific format.\n-\n-#### `listAdapters()`\n-\n-List all registered adapter names.\n-\n-### Options\n-\n-```typescript\n-interface ZTFOptions {\n-  adapter?: Record<string, unknown>; // Custom options for the specific adapter\n-  validate?: boolean; // Whether to validate the output against the schema\n-  includeProvenance?: boolean; // Whether to include provenance metadata in result\n-  deterministic?: boolean; // Whether to enforce deterministic output\n-  streaming?: boolean; // Whether to use streaming for large datasets\n+try {\n+  const result = await parseFrom(Schema, 'json', invalidData);\n+} catch (error) {\n+  if (error.name === 'ZodError') {\n+    console.log('Schema validation failed:', error.issues);\n+  } else {\n+    console.log('Parsing failed:', error.message);\n+  }\n }\n ```\n \n ## üß™ Testing\n \n ```bash\n-# Run tests\n+# Run all tests\n pnpm test\n \n-# Run tests with coverage\n-pnpm test --coverage\n+# Run specific test suites\n+pnpm test:unit\n+pnpm test:adapters\n+pnpm test:e2e\n \n-# Run linting\n-pnpm lint\n-\n-# Fix linting issues\n-pnpm lint:fix\n+# Run with coverage\n+pnpm test:coverage\n ```\n \n-### ü§ñ AI Adapter Testing\n+## üìà Performance\n \n-The AI adapters include comprehensive tests that verify integration with Ollama\n-models. These tests are **opt-in only** to keep the regular test suite fast:\n+ZTF is designed for performance:\n \n-```bash\n-# Run AI adapter tests (requires Ollama running locally)\n-pnpm test:ai\n+- **Zero Dependencies** - Core library has no external dependencies\n+- **Lazy Loading** - Adapters are loaded only when needed\n+- **Streaming Support** - Handle large datasets without memory issues\n+- **Efficient Parsing** - Optimized for common use cases\n \n-# Run AI adapter tests in watch mode\n-pnpm test:ai:watch\n+## ü§ù Contributing\n \n-# Run regular tests (AI tests are skipped by default)\n-pnpm test\n-```\n+We welcome contributions! Please see our\n+[Contributing Guide](docs/contributing/README.md) for details.\n \n-**Prerequisites for AI tests:**\n+### Development Setup\n \n-- Ollama installed and running locally\n-- At least one model available (e.g., `qwen3-coder`, `qwen3:8b`)\n-- Test files available in\n-  `node_modules/.pnpm/mammoth@*/node_modules/mammoth/test/test-data/`\n+```bash\n+# Clone the repository\n+git clone https://github.com/your-org/zod-to-from.git\n+cd zod-to-from\n \n-The AI tests verify:\n+# Install dependencies\n+pnpm install\n \n-- ‚úÖ Real document processing (DOCX files)\n-- ‚úÖ Multiple model support\n-- ‚úÖ Custom prompt handling\n-- ‚úÖ Schema validation\n-- ‚úÖ Error handling\n+# Run development server\n+pnpm dev\n \n+# Run tests\n+pnpm test\n+```\n+\n ## üìÑ License\n \n-MIT License - see [LICENSE](LICENSE) for details.\n+MIT License - see [LICENSE](LICENSE) file for details.\n \n-## ü§ù Contributing\n+## üôè Acknowledgments\n \n-Contributions are welcome! Please read our contributing guidelines and submit\n-pull requests to our repository.\n+- [Zod](https://github.com/colinhacks/zod) for schema validation\n+- [Ollama](https://ollama.ai/) for AI capabilities\n+- All the open-source libraries that power our adapters\n \n-## üìö Documentation\n+## üìû Support\n \n-- [API Reference](./docs/api.md)\n-- [Adapter Development Guide](./docs/adapters.md)\n-- [CLI Usage Guide](./docs/cli.md)\n-- [Security Best Practices](./docs/security.md)\n+- üìñ [Documentation](docs/README.md)\n+- üêõ [Issue Tracker](https://github.com/your-org/zod-to-from/issues)\n+- üí¨ [Discussions](https://github.com/your-org/zod-to-from/discussions)\n+- üìß [Email Support](mailto:support@example.com)\n \n ---\n \n-**zod-to-from** - Making Zod the universal intermediate representation for all\n-application I/O.\n+**Made with ‚ù§Ô∏è by the ZTF Team**\n"
                },
                {
                    "date": 1759006242858,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,16 +1,24 @@\n-# Zod-to-From (ZTF)\n+# Zod-to-From (ZTF) v1.0.0\n \n > **A comprehensive format conversion library with Zod schema validation**\n \n ZTF is a powerful, extensible library that provides seamless conversion between\n various data formats while ensuring type safety through Zod schema validation.\n Whether you're working with JSON, YAML, CSV, or specialized formats like GPX,\n KML, or Office documents, ZTF has you covered.\n \n+## üÜï What's New in v1.0.0\n+\n+- **New `from/to` API** - Clean, intuitive function naming\n+- **47 Format Adapters** - Comprehensive format support\n+- **94 Export Functions** - Direct access to all adapters\n+- **Improved Type Safety** - Better JSDoc documentation\n+- **Enhanced Testing** - Comprehensive test coverage\n+\n ## üöÄ Features\n \n-- **42+ Format Adapters** - Support for JSON, YAML, CSV, XML, Office documents,\n+- **47 Format Adapters** - Support for JSON, YAML, CSV, XML, Office documents,\n   geospatial data, and more\n - **Zod Schema Validation** - Type-safe data conversion with runtime validation\n - **AI-Powered Adapters** - Intelligent parsing for complex documents using\n   Ollama\n@@ -34,9 +42,42 @@\n ```\n \n ## üéØ Quick Start\n \n+### New `from/to` API (v1.0.0)\n+\n ```javascript\n+import { fromJson, toJson, fromCsv, toCsv, fromYaml, toYaml } from 'zod-to-from';\n+\n+// Parse JSON to structured data\n+const jsonData = '{\"name\": \"Alice\", \"age\": 30, \"email\": \"alice@example.com\"}';\n+const user = await fromJson(jsonData);\n+console.log(user.data); // { name: \"Alice\", age: 30, email: \"alice@example.com\" }\n+\n+// Format structured data to JSON\n+const jsonOutput = await toJson({ name: \"Bob\", age: 25, email: \"bob@example.com\" });\n+console.log(jsonOutput.data);\n+// {\n+//   \"name\": \"Bob\",\n+//   \"age\": 25,\n+//   \"email\": \"bob@example.com\"\n+// }\n+\n+// Parse CSV to structured data\n+const csvData = 'name,age,email\\nCharlie,35,charlie@example.com';\n+const csvResult = await fromCsv(csvData);\n+console.log(csvResult.data.data); // [{ name: \"Charlie\", age: 35, email: \"charlie@example.com\" }]\n+\n+// Format structured data to CSV\n+const csvOutput = await toCsv([{ name: \"David\", age: 40, email: \"david@example.com\" }]);\n+console.log(csvOutput.data);\n+// name,age,email\n+// David,40,david@example.com\n+```\n+\n+### Legacy API (still supported)\n+\n+```javascript\n import { parseFrom, formatTo, convert } from 'zod-to-from';\n import { z } from 'zod';\n \n // Define your schema\n@@ -56,18 +97,8 @@\n console.log(yamlOutput);\n // name: Alice\n // age: 30\n // email: alice@example.com\n-\n-// Convert between formats\n-const csvInput = 'name,age,email\\nBob,25,bob@example.com';\n-const jsonOutput = await convert(\n-  UserSchema,\n-  { from: 'csv', to: 'json' },\n-  csvInput\n-);\n-console.log(jsonOutput);\n-// [{\"name\": \"Bob\", \"age\": 25, \"email\": \"bob@example.com\"}]\n ```\n \n ## üìö Documentation\n \n@@ -265,9 +296,9 @@\n ### Development Setup\n \n ```bash\n # Clone the repository\n-git clone https://github.com/your-org/zod-to-from.git\n+git clone https://github.com/sac/zod-to-from.git\n cd zod-to-from\n \n # Install dependencies\n pnpm install\n@@ -291,10 +322,10 @@\n \n ## üìû Support\n \n - üìñ [Documentation](docs/README.md)\n-- üêõ [Issue Tracker](https://github.com/your-org/zod-to-from/issues)\n-- üí¨ [Discussions](https://github.com/your-org/zod-to-from/discussions)\n+- üêõ [Issue Tracker](https://github.com/sac/zod-to-from/issues)\n+- üí¨ [Discussions](https://github.com/sac/zod-to-from/discussions)\n - üìß [Email Support](mailto:support@example.com)\n \n ---\n \n"
                }
            ],
            "date": 1758642289491,
            "name": "Commit-0",
            "content": "# zod-to-from\n\n<!-- automd:badges color=yellow -->\n\n[![npm version](https://img.shields.io/npm/v/zod-to-from?color=yellow)](https://npmjs.com/package/zod-to-from)\n[![npm downloads](https://img.shields.io/npm/dm/zod-to-from?color=yellow)](https://npm.chart.dev/zod-to-from)\n\n<!-- /automd -->\n\nA collection of to/from adapters that convert between I/O formats and Zod-validated objects. The library is designed with a \"one schema in the middle, many edges around it\" philosophy, providing a schema-centric I/O hub for JavaScript. It is a build-less, ESM-only library using `.mjs` files with JSDoc for type safety.\n\n### ‚ú® Features\n\n  * **Schema-Centric:** Uses a single Zod schema as the central contract for all I/O operations.\n  * **Massive Converter Catalog:** Supports a wide range of formats through optional packs, including Office documents, data analytics formats, config files, and knowledge graphs.\n  * **Symmetric API:** Provides a simple and symmetrical API with three core functions: `parseFrom`, `formatTo`, and `convert`.\n  * **Deterministic Outputs:** Enforces deterministic I/O with stable key ordering and consistent formatting policies for dates and numbers.\n  * **Buildless by Design:** Uses `.mjs` and JSDoc to ensure a build-free, portable runtime that works in Node, Deno, and edge environments.\n  * **Optional AI Adapters:** Can leverage the Vercel AI SDK and Ollama to normalize \"messy\" formats like Office documents into a structured schema.\n  * **First-Class RDF/Turtle Support:** Treats Turtle as a universal Intermediate Representation (IR), unlocking capabilities for knowledge-driven automation, governance, and provenance.\n  * **Monorepo Structure:** Organized as a pnpm workspace with a small core library and optional packs for different format categories.\n\n### üöÄ Quick Start\n\n**1. Installation**\n\n```bash\n# Install the core library and zod\nnpm i zod-to-from zod\n\n# Install optional packs as needed\nnpm i ztf-pack-office ztf-pack-data ztf-pack-graph\n```\n\n**2. Usage**\n\n```javascript\nimport { z } from 'zod';\nimport { convert, parseFrom, formatTo } from 'zod-to-from';\n\n// 1) Define your Zod schema\nconst Config = z.object({\n  host: z.string(),\n  port: z.number().int().positive(),\n  debug: z.boolean().default(false)\n});\n\n// 2) Parse from a format (e.g., YAML) into a validated object\nconst obj = await parseFrom(Config, 'yaml', `\nhost: api.example.com\nport: 8443\ndebug: true\n`);\n\n// 3) Format the object into another format (e.g., TOML)\nconst toml = await formatTo(Config, 'toml', obj);\n\n// 4) Convert between formats in a single step\nconst toml2 = await convert(Config, { from: 'yaml', to: 'toml' }, `\nhost: api.example.com\nport: 8443\n`);\n```\n\n### üì¶ API\n\n  * `parseFrom(schema, format, input, opts?)`: Parses input from a specified format into a Zod-validated object.\n  * `formatTo(schema, format, data, opts?)`: Formats a validated object into the specified output format.\n  * `convert(schema, { from, to }, input, opts?)`: A one-shot function to convert from an input format to an output format.\n  * `registerAdapter(name, adapter)`: Allows for adding custom format converters at runtime.\n  * `listAdapters()`: Returns a list of available adapters.\n\n### üìö Converter Packs (The 80/20 \"Dark Matter\")\n\nZTF covers the \"dark matter\" of heterogeneous I/O formats through a series of optional packs.\n\n| Pack | Formats | Shape |\n| --- | --- | --- |\n| **Office & Exec Outputs** | `docx-table`, `pptx-slides`, `xlsx`, `pdf-table`, `md`, `html`, `csv` | doc, table |\n| **Data & Analytics** | `json`, `ndjson`, `parquet`, `arrow`, `avro`, `protobuf`, `sqlite` | tree, records, table |\n| **Graph & Knowledge** | `ttl`, `nq`, `jsonld`, `plantuml`, `mermaid`, `openapi`, `jsonschema` | graph, diagram |\n| **DevOps & Config** | `yaml`, `toml`, `ini`, `env`, `dockerfile`, `compose`, `k8s` | tree, records |\n| **Nunjucks** | `njk`, `md`, `html`, `puml`, `ttl`, `frontmatter` (parse) | doc |\n| **Communications** | `ics`, `vcard`, `eml`, `msgpack`, `har`, `curl` | calendar, contact, message |\n| **Media & Meta** | `exif`, `id3`, `base64`, `zip`, `tar`, `pdf-text` | tree, blob, doc |\n| **Geo & Time** | `geojson`, `topojson`, `kml`, `gpx`, `wkt` | tree |\n\n### ü§ñ AI-Assisted Adapters\n\nFor \"messy\" formats with implicit structure, ZTF provides optional AI-powered adapters.\n\n  * **`office-ai` Pack:** Uses the Vercel AI SDK and Ollama to parse formats like `.docx`, `.pptx`, and `.xlsx` by extracting their content and normalizing it into a target Zod schema.\n  * **Ingestion Only:** This AI-powered normalization is used only for `parseFrom` operations. The `formatTo` operation for creating documents remains deterministic.\n  * **Provenance:** Outputs from AI adapters are tagged with metadata, such as the LLM model used, for auditability.\n\n### üîß CLI (Optional)\n\nZTF includes an optional CLI for command-line conversions.\n\n```bash\n# Parse a YAML file into a JSON object\nnpx ztf parse --schema ./schemas/config.mjs#Config --from yaml --in config.yaml --out config.json\n\n# Format a JSON object into a TOML file\nnpx ztf format --schema ./schemas/config.mjs#Config --to toml --in config.json --out config.toml\n\n# Convert a CSV file directly to an XLSX spreadsheet\nnpx ztf convert --schema ./schemas/report.mjs#Report[] --from csv --to xlsx --in data.csv --out out.xlsx\n```\n\n## Usage\n\nInstall the package:\n\n```sh\n# ‚ú® Auto-detect (supports npm, yarn, pnpm, deno and bun)\nnpx nypm install zod-to-from\n```\n\nImport:\n\n<!-- automd:jsimport cdn name=\"zod-to-from\" -->\n\n**ESM** (Node.js, Bun, Deno)\n\n```js\nimport { parseFrom, formatTo, convert } from \"zod-to-from\";\n```\n\n**CDN** (Deno, Bun and Browsers)\n\n```js\nimport { parseFrom, formatTo, convert } from \"https://esm.sh/zod-to-from\";\n```\n\n<!-- /automd -->\n\n## Development\n\n<details>\n\n<summary>local development</summary>\n\n- Clone this repository\n- Install latest LTS version of [Node.js](https://nodejs.org/en/)\n- Enable [Corepack](https://github.com/nodejs/corepack) using `corepack enable`\n- Install dependencies using `pnpm install`\n- Run interactive tests using `pnpm dev`\n\n</details>\n\n## License\n\n<!-- automd:contributors license=MIT -->\n\nPublished under the [MIT](https://github.com/unjs/zod-to-from/blob/main/LICENSE) license.\nMade by [community](https://github.com/unjs/zod-to-from/graphs/contributors) üíõ\n<br><br>\n<a href=\"https://github.com/unjs/zod-to-from/graphs/contributors\">\n<img src=\"https://contrib.rocks/image?repo=unjs/zod-to-from\" />\n</a>\n\n<!-- /automd -->\n\n<!-- automd:with-automd -->\n\n---\n\n_ü§ñ auto updated with [automd](https://automd.unjs.io)_\n\n<!-- /automd -->\n"
        }
    ]
}